{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"140fde94-b47d-4f01-b865-f845601f6db1\",\n",
      "  \"summary\": \"Here's a summary of the YouTube video about Grok 4 vs. ChatGPT:\\n\\n### Grok 4 vs. ChatGPT: Key Differences and Capabilities\\n\\n*   **Real-Time Information:**\\n    *   Grok 4 has native web search and X (Twitter) integration, providing real-time data.\\n    *   ChatGPT relies on static training data with occasional browsing.\\n\\n*   **Reasoning Capabilities:**\\n    *   Grok 4 outperformed competitors in reasoning tests (Humanity's Last Exam, Data Camp's business simulation).\\n    *   Grok 4 uses a \\\"heavy mode\\\" with multiple AI agents for parallel debate and insight synthesis.\\n\\n*   **Personality and Communication:**\\n    *   Grok 4 offers personality, wit, and sarcasm, aiming for engaging conversations.\\n    *   ChatGPT provides more sanitized, corporate-style responses.\\n\\n*   **Multimedia and Content Creation:**\\n    *   ChatGPT currently has more polished tools for content creation and image generation.\\n    *   Grok 4 plans to launch multimodal capabilities (video generation) soon.\\n\\n*   **Integrated Tools:**\\n    *   Grok 4 has tools built directly into its reasoning process (e.g., Python interpreter).\\n    *   ChatGPT relies on plugins and external integrations.\\n\\n*   **Unfiltered Communication:**\\n    *   Grok 4 offers unfiltered, nuanced responses, avoiding corporate speak.\\n    *   ChatGPT has extensive safety filters and corporate guidelines.\\n\\n*   **Speed and Pricing:**\\n    *   ChatGPT is faster for simple queries.\\n    *   Grok 4 trades speed for depth and analysis.\\n    *   ChatGPT: $20/month with a free tier.\\n    *   Grok 4: $30/month (X Premium Plus required), $300 \\\"Super Grok\\\" tier available.\\n\\n### Verdict\\n\\n*   ChatGPT excels as a creative partner and general-purpose AI assistant.\\n*   Grok 4 is designed for users needing cutting-edge reasoning, real-time information, and authentic dialogue.\\n*   Grok 4 represents advances in AI reasoning and real-time data access.\",\n",
      "  \"transcript\": \"Picture this. You're asking your AI assistant about breaking news that happened 5 minutes ago. ChatGpt gives you information from last year, while Gro 4 pulls up real-time data and delivers current insights. That's just the beginning of what I discovered since Grog 4's launch just over a week ago. And what I found in the reasoning department will change how you think about AI capabilities. Welcome back to bitbias.ai, where we do the research so you don't have to. Since Gro 4 dropped on July 9th, I've been diving deep into testing both systems across 11 categories, and the results revealed clear winners in areas that might surprise you. Before we dive in, hit subscribe because the AI landscape is evolving weekly, and what's coming in September alone will reshape everything we know about AI assistance, the real time information revolution. Let me start with something that fundamentally changes the game. While chat GPT relies on static training data with occasional browsing features, Gro 4 was built with native web search and direct Xplatform integration. When you ask it a question, it actively searches the internet and pulls from X's real-time data stream. I tested this with everything from stock updates to breaking news, and the difference is significant. Chat GPT gives you context and background, but Grock 4 gives you what's happening right now. For anyone tracking markets, following news cycles, or staying current, this isn't just an advantage. It's a different category of capability. But here's where it gets really interesting. Groke doesn't just find current information. It synthesizes it with contextual understanding that most humans would miss. Wait until you see what this means for complex problem solving. The reasoning breakthrough. This discovery was surprising. On humanity's last exam, the benchmark designed to test AI reasoning limits. Grock 4 didn't just win. It performed notably better than competitors. But the real revelation came from Data Camp's business simulation test where AI models ran virtual businesses over hundreds of rounds. Grock four more than doubled the net worth achieved by the next best model. This isn't just better pattern recognition. This is fundamentally superior strategic thinking. The secret lies in heavy mode where multiple AI agents run in parallel debate approaches and synthesize insights. It's like having expert consultants working on your problem instead of one adviser. I've used this for investment analysis and project planning, and the depth of insight is unlike anything I've experienced with other AI systems. But here's what really impressed me about how Grock handles communication. If you're finding this breakdown helpful, please consider subscribing to the channel. It directly supports our ability to dive deep into the research on new AI releases in this rapidly evolving landscape, so we can continue bringing you these detailed comparisons as they launch. The personality and multimedia reality Grock 4 takes a completely different approach to interaction. You're not getting sanitized corporate responses. You're getting personality, wit, and sometimes sarcasm. It reflects Elon's philosophy that AI should be engaging, not just safe and predictable. I found myself having actual conversations rather than just sessions. Now, I need to be honest. If you're focused on content creation or image generation, ChatGpt currently has more polished tools. The GPT store, Dolly integration, and voice features create a smooth creative workflow that Grock doesn't match yet. But XAI's roadmap shows true multimodal capabilities launching in September with video generation in October. Knowing Elon's track record with product launches, these aren't just incremental updates. Based on the reasoning capabilities I've seen, Grock's upcoming multimedia features could significantly improve AI creativity tools. The integrated tools advantage. This reveals Groke 4's true architectural advantage. While chat GPT relies on plugins and external integrations, Gro was trained with tools built directly into its reasoning process. Watch what happens when I ask both systems to analyze a market trend. Chat GPT accesses training data and might use browsing plugins. Gro 4 automatically searches current web data, analyzes social media sentiment, runs calculations through its integrated Python interpreter, and synthesizes everything into actionable insights. The difference isn't just capabilities. It's seamless integration with the AI's thinking process. I've used this for market analysis and competitive research, consistently finding Grock's integrated approach produces more complete and actionable insights than other systems, even with multiple plugins. But here's what really sets Groke apart in authentic interaction. The unfiltered advantage. There's a fundamental philosophical difference these systems approach information. Chat GPT has extensive safety filters and corporate guidelines. When you ask about controversial topics, you often get carefully crafted non-answers that feel like corporate communications. Grock 4 takes Elon's free speech philosophy seriously. It doesn't hide behind corporate speak or refuse to engage with complex topics. You get thoughtful, nuanced responses rather than sanitized talking points. This means being more thoughtful about questions, but you get authentic insights where other systems give press releases. For research or strategic planning where you need unvarnished analysis, this difference becomes valuable. Grock treats you like an adult capable of handling complex nuanced information resulting in conversations that feel authentic and insights that are more direct. The speed and pricing reality. Yes, ChatGpt responds faster on simple queries, but Groke 4 trades speed for depth. When ChatgPT gives quick responses, Grock considers multiple angles, checks current data, and runs deeper analysis. That massive 256,000 token context window means maintaining perfect conversation continuity through complex research projects. Let's talk cost, honestly. Chat GPT costs $20 monthly with a free tier. Gro 4 requires X Premium Plus at $30 with no free option. But you're not just paying for AI access. You're getting real-time data, unfiltered communication, and X ecosystem integration, plus betting on XAI's aggressive roadmap. The $300 Super Grock heavy tier provides the most powerful reasoning system available. For professionals doing serious analysis, that capability could easily pay for itself. But for most users, the $30 tier provides access to capabilities that don't exist elsewhere. The verdict. After intensive testing since its July 9th launch, these aren't really competing products. They're designed for different use cases and philosophies, ChatGpt excels as a creative partner and multimedia assistant, remaining excellent for content creation and general purpose AI assistance. But Groke 4 operates in a different category. It's designed for users needing cuttingedge reasoning, real-time information access, and authentic dialogue without corporate filtering. The benchmark results reflect genuine advances in AI reasoning that translate into practical advantages for complex tasks. The integration of real-time data, advanced reasoning agents, and unfiltered communication creates an AI experience that feels less like using a tool and more like consulting an incredibly knowledgeable expert with unlimited computational power. The AI landscape is evolving rapidly. And what we're seeing with Gro 4 represents significant advances in reasoning capabilities and real-time information access. If this comparison helped you understand the key differences between these systems, let me know in the comments what aspects you found most interesting. Don't forget to subscribe to our weekly newsletter at bitbias.ai to stay uptodate with the latest in AI developments. We'll continue covering new releases and major updates as they happen in this fastmoving space. Thanks for watching and I'll see you in the next one.\",\n",
      "  \"metadata\": {\n",
      "    \"timestamp\": \"2025-07-18T10:51:54.410033\",\n",
      "    \"video_id\": \"dvoLEF4oVtc\",\n",
      "    \"options\": {\n",
      "      \"format\": \"markdown\",\n",
      "      \"length\": \"medium\",\n",
      "      \"language\": \"english\",\n",
      "      \"include_sentiment\": false,\n",
      "      \"include_keywords\": false\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the URL for the API\n",
    "url = \"http://localhost:8000/summarize/youtube\"\n",
    "\n",
    "# Define the data payload\n",
    "data = {\n",
    "    \"url\": \"https://youtu.be/dvoLEF4oVtc?feature=shared\",\n",
    "    \"options\": {\n",
    "        \"format\": \"markdown\",\n",
    "        \"length\": \"medium\",\n",
    "        \"language\": \"english\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Send the POST request to the FastAPI server\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Print the response from the API (e.g., summary)\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add(a,b):\n",
    "    return a+b\n",
    "\n",
    "def sub(a,b):\n",
    "    return a-b\n",
    "\n",
    "def mul(a,b):\n",
    "    return a*b\n",
    "\n",
    "\n",
    "def div(a,b):\n",
    "    return a/b\n",
    "\n",
    "def show_result(a,b):\n",
    "    print(f\"Addition of {a} and {b} is {add(a,b)}\")\n",
    "    print(f\"Subtraction of {a} and {b} is {sub(a,b)}\")\n",
    "    print(f\"Multiplication of {a} and {b} is {mul(a,b)}\")\n",
    "    print(f\"Division of {a} and {b} is {div(a,b)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI ,HTTPException\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "def add(a:float,b:float)->float:\n",
    "    return a+b\n",
    "\n",
    "def sub(a:float,b:float)->float:\n",
    "    return a-b\n",
    "\n",
    "def mul(a:float,b:float)->float:\n",
    "    return a*b\n",
    "def divd(a:float,b:float)->float:\n",
    "    try:\n",
    "        return a/b\n",
    "    except ZeroDivisionError:\n",
    "        raise HTTPException(status_code=400,detail=\"Division by zero is not allowed\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/add\")\n",
    "def add_number(a:float,b:float):\n",
    "    result = add(a,b)\n",
    "    return {\"function\":\"add\",\"result\":result}\n",
    "\n",
    "@app.get(\"/sub\")\n",
    "def sub_number(a:float,b:float):\n",
    "    result = sub(a,b)\n",
    "    return {\"function\":\"sub\",\"result\":result}\n",
    "\n",
    "@app.get(\"mul\")\n",
    "def mul_number(a,b):\n",
    "    result = mul(a,b)\n",
    "    return {\"function\":\"mul\",\"result\":result}\n",
    "\n",
    "@app.get(\"div\")\n",
    "def div_number(a:float,b:float):\n",
    "    result = divd(a,b)\n",
    "    return {\"function\":\"div\",\"result\":result}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def show_result(a:float,b:float):\n",
    "#     add_result=add(a,b)\n",
    "#     sub_result=sub(a,b)\n",
    "#     mul_result=mul(a,b)\n",
    "#     div_result=divd(a,b)\n",
    "#     print(f\"Addition of {a} and {b} is {add_result}\")\n",
    "#     print(f\"Subtraction of {a} and {b} is {sub_result}\")\n",
    "#     print(f\"Multiplication of {a} and {b} is {mul_result}\")\n",
    "#     print(f\"Division of {a} and {b} is {div_result}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found video file: /home/prabhakarkumar/Prabhakar/prabhakar personal projects/video summary generator/2025-07-20-190710.webm\n",
      "File size: 0.92 MB\n",
      "Starting transcription of: /home/prabhakarkumar/Prabhakar/prabhakar personal projects/video summary generator/2025-07-20-190710.webm\n",
      "Loading video file...\n",
      "Extracting audio...\n",
      "Transcribing audio...\n",
      "Transcription completed successfully!\n",
      "Cleaning up temporary files...\n",
      "\n",
      "==================================================\n",
      "TRANSCRIPT:\n",
      "==================================================\n",
      "hello can you hear me I am saying something please understand at let me know what I am saying ok\n",
      "==================================================\n",
      "Transcript saved to: transcript_20250720_192047.txt\n",
      "\n",
      "Transcript saved to: transcript_20250720_192047.txt\n",
      "Transcript length: 96 characters\n",
      "Approximate word count: 20\n"
     ]
    }
   ],
   "source": [
    "# Video Transcription Script\n",
    "# Run this in Jupyter notebook to transcribe your video\n",
    "\n",
    "import speech_recognition as sr\n",
    "import moviepy.editor as mp\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "def transcribe_video(video_path):\n",
    "    \"\"\"\n",
    "    Transcribe audio from a video file using Google Speech Recognition\n",
    "    \"\"\"\n",
    "    print(f\"Starting transcription of: {video_path}\")\n",
    "    \n",
    "    # Create temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    try:\n",
    "        # Load the video file\n",
    "        print(\"Loading video file...\")\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "        \n",
    "        # Extract audio\n",
    "        print(\"Extracting audio...\")\n",
    "        audio_path = os.path.join(temp_dir, \"temp_audio.wav\")\n",
    "        video.audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
    "        \n",
    "        # Initialize recognizer\n",
    "        recognizer = sr.Recognizer()\n",
    "        \n",
    "        # Transcribe audio\n",
    "        print(\"Transcribing audio...\")\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            # Adjust for ambient noise\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "            \n",
    "            # Record audio\n",
    "            audio = recognizer.record(source)\n",
    "            \n",
    "            # Recognize speech\n",
    "            transcript = recognizer.recognize_google(audio)\n",
    "            \n",
    "        print(\"Transcription completed successfully!\")\n",
    "        return transcript\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during transcription: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temporary files\n",
    "        print(\"Cleaning up temporary files...\")\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "def save_transcript(transcript, output_path=None):\n",
    "    \"\"\"\n",
    "    Save transcript to a text file\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = f\"transcript_{timestamp}.txt\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(transcript)\n",
    "    \n",
    "    print(f\"Transcript saved to: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Your video path\n",
    "    video_path = \"/home/prabhakarkumar/Prabhakar/prabhakar personal projects/video summary generator/2025-07-20-190710.webm\"\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file not found at {video_path}\")\n",
    "    else:\n",
    "        print(f\"Found video file: {video_path}\")\n",
    "        print(f\"File size: {os.path.getsize(video_path) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        # Transcribe the video\n",
    "        transcript = transcribe_video(video_path)\n",
    "        \n",
    "        if transcript:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"TRANSCRIPT:\")\n",
    "            print(\"=\"*50)\n",
    "            print(transcript)\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # Save transcript\n",
    "            output_file = save_transcript(transcript)\n",
    "            \n",
    "            # Display file info\n",
    "            print(f\"\\nTranscript saved to: {output_file}\")\n",
    "            print(f\"Transcript length: {len(transcript)} characters\")\n",
    "            print(f\"Approximate word count: {len(transcript.split())}\")\n",
    "        else:\n",
    "            print(\"Failed to transcribe video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_summary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
